\documentclass[11pt]{article}

% This first part of the file is called the PREAMBLE. It includes
% customizations and command definitions. The preamble is everything
% between \documentclass and \begin{document}.

\usepackage[margin=0.6in]{geometry} % set the margins to 1in on all sides
\usepackage{graphicx} % to include figures
\usepackage{amsmath} % great math stuff
\usepackage{amsfonts} % for blackboard bold, etc
\usepackage{amsthm} % better theorem environments
% various theorems, numbered by section
\usepackage{amssymb}
\usepackage[utf8]{inputenc}
\usepackage{booktabs}
\usepackage{array}
\usepackage{courier}
\usepackage[usenames, dvipsnames]{color}
\usepackage{titlesec}
\usepackage{empheq}
\usepackage{tikz}

\newcommand\encircle[1]{%
  \tikz[baseline=(X.base)] 
    \node (X) [draw, shape=circle, inner sep=0] {\strut #1};}
 
% Command "alignedbox{}{}" for a box within an align environment
% Source: http://www.latex-community.org/forum/viewtopic.php?f=46&t=8144
\newlength\dlf  % Define a new measure, dlf
\newcommand\alignedbox[2]{
% Argument #1 = before & if there were no box (lhs)
% Argument #2 = after & if there were no box (rhs)
&  % Alignment sign of the line
{
\settowidth\dlf{$\displaystyle #1$}  
    % The width of \dlf is the width of the lhs, with a displaystyle font
\addtolength\dlf{\fboxsep+\fboxrule}  
    % Add to it the distance to the box, and the width of the line of the box
\hspace{-\dlf}  
    % Move everything dlf units to the left, so that & #1 #2 is aligned under #1 & #2
\boxed{#1 #2}
    % Put a box around lhs and rhs
}
}


\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{conj}[thm]{Conjecture}

\setcounter{secnumdepth}{4}

\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\definecolor{myblue}{RGB}{72, 165, 226}
\definecolor{myorange}{RGB}{222, 141, 8}

\setlength{\heavyrulewidth}{1.5pt}
\setlength{\abovetopsep}{4pt}


\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\argmin}{\arg\!\min}
\DeclareMathOperator{\Tr}{Tr}

\newcommand{\bd}[1]{\mathbf{#1}} % for bolding symbols
\newcommand{\RR}{\mathbb{R}} % for Real numbers
\newcommand{\ZZ}{\mathbb{Z}} % for Integers
\newcommand{\col}[1]{\left[\begin{matrix} #1 \end{matrix} \right]}
\newcommand{\comb}[2]{\binom{#1^2 + #2^2}{#1+#2}}
\newcommand{\bs}{\boldsymbol}
\newcommand{\opn}{\operatorname}
\begin{document}
\nocite{*}

\title{Exploratory data analysis}

\author{Daeyoung Lim\thanks{Prof. Taeryon Choi} \\
Department of Statistics \\
Korea University}

\maketitle
\section{Pendulum Data}
\subsection{Data Description}
The pendulum data obtained from the paper of David Nott consists of 9 covariates and one target variable. As described in the original paper, it is a simulated data of mechanical pendulum, covariates of which are different parameters of the system and the target variable is the angular velocity.
\section{SSGP}
  For a short summary of Lazaro Gredilla's SSGP, the paper comes up with a decomposition of the function into
  \begin{equation}
    f\left(\mathbf{x}\right) = \sum_{r=1}^{m}a_{r}\cos\left(2\pi \mathbf{s}_{r}^{\top}\mathbf{x}\right) + b_{r}\sin\left(2\pi\mathbf{s}_{r}^{\top}\mathbf{x}\right)
  \end{equation}
  where $a_{r}\sim \mathcal{N}\left(0, m^{-1}\sigma_{0}^{2}\right)$, $b_{r} \sim \mathcal{N}\left(0,m^{-1}\sigma_{0}^{2}\right)$. Then, by transforming $\mathbf{x}$ into
  \begin{equation}
    \phi\left(\mathbf{x}\right) = \begin{bmatrix} \cos\left(2\pi\mathbf{s}_{1}^{\top}\mathbf{x}\right) & \sin\left(2\pi\mathbf{s}_{1}^{\top}\mathbf{x}\right) & \cdots & \cos\left(2\pi\mathbf{s}_{m}^{\top}\mathbf{x}\right) & \sin\left(2\pi\mathbf{s}_{m}^{\top}\mathbf{x}\right) \end{bmatrix},
  \end{equation}
  the end result becomes similar to linear Gaussian process regression model:
  \begin{align}
    \opn{E}\left(\mathbf{y}_{*}\right) &= \phi\left(\mathbf{x}_{*}\right)^{\top}A^{-1}\mathbf{\Phi}\mathbf{y}\\
    \opn{Var}\left(\mathbf{y}_{*}\right) &= \sigma_{n}^{2}+\sigma_{n}^{2}\phi\left(\mathbf{x}_{*}\right)^{\top}A^{-1}\phi\left(\mathbf{x}_{*}\right).
  \end{align}
  The author suggests learning the parameters via optimizing the log-marginal likelihood:
  \begin{equation}
    \log p\left(\mathbf{y}|\theta\right) = -\frac{1}{2\sigma_{n}^{2}}\left(\mathbf{y}^{\top}\mathbf{y}-\mathbf{y}^{\top}\mathbf{\Phi}^{\top}A^{-1}\mathbf{\Phi y}\right)-\frac{1}{2}\log \left|A\right| +m\log\frac{m\sigma_{m}^{2}}{\sigma_{0}^{2}}-\frac{n}{2}\log\left(2\pi\sigma_{n}^{2}\right)
  \end{equation}
  by means of the conjugate gradient method.
\subsection{Sidenote}
  The predictive mean of Gaussian process regression model is
  \begin{align}
    p\left(f_{*}|\mathbf{x}_{*}, X, \mathbf{y}\right) &= \int p\left(f_{*}|\mathbf{x}_{*}, \mathbf{w}\right)p\left(\mathbf{w}|X,\mathbf{y}\right)\,d\mathbf{w} = \int \mathbf{x}_{*}^{\top}\mathbf{w}p\left(\mathbf{w}|X,\mathbf{y}\right)\,d\mathbf{w}\\
    &=\mathcal{N}\left(\frac{1}{\sigma_{n}^{2}}\mathbf{x}_{*}^{\top}A^{-1}X\mathbf{y}, \mathbf{x}_{*}^{\top}A^{-1}\mathbf{x}_{*}\right).
  \end{align}
  The posterior distribution of the weights $\mathbf{w}$ is
  \begin{equation}
    p\left(\mathbf{w}|X,\mathbf{y}\right) \sim \mathcal{N}\left(\overline{\mathbf{w}}=\frac{1}{\sigma_{n}^{2}}A^{-1}X\mathbf{y}, A^{-1}\right)
  \end{equation}
  where $A = \sigma_{n}^{-2}XX^{\top}+\Sigma_{p}^{-1}$. Therefore, this is the reason why we can plug in the test data $\overset{\sim}{X}$ into the predictive distribution's $\mathbf{x}_{*}$ to get the fitted values of the unknown function, $\hat{f}$. (In the case of sparse spectrum decomposition, the design matrix is no longer $X$ but rather $\Phi$.)
\section{VA for partially linear additive models}
The paper suggests a model of the form
\begin{equation}
  y_{i} = \mu + \sum_{j=1}^{p}f_{j}\left(x_{ij}\right) + \epsilon_{i}, \quad i = 1, \ldots , n.
\end{equation}
\begin{itemize}
  \item In the authors' exact words, \textit{for simplicity of exposition}, they assumed all covariates to be continuous with support $\left[0, 1\right]$.
  \item Discrete variables are put into the linear part.
  \item Impose $\opn{E}\left(f_{j}\left(x_{j}\right)\right)=0$ constraint to achieve identiability.
  \item Transform the basis functions in such a way that they are orthogonal to the linear basis functions.
  \item Essentially VB for parameter estimation but offered some degree of freedom between Monte Carlo estimation and Laplace approximation for the intractable integration terms.
\end{itemize}
The real data analysis section of the original paper mentions that the crime data in \textsf{R} package \{\textsf{Ecdat}\} was used, which has 630 observations and 22 variables. 
\subsection{BPLAM code review}
  \begin{itemize}
  \item Since one of the purposes of this paper was to propose a novel way of selecting variables using variational approximation, the code assumes there would be more than one covariate. The code crashes with only \texttt{x} of one column.
  \item The code still worked even though one of the covariates was outside of the range $\left[0,1\right]$.\\
  \item Functions are not self-contained!!!!! Who codes like this!?
  \end{itemize}
\section{Kneib VA}
Model:
\begin{equation}
  y_{i} = \mathbf{x}^{\top}\bs{\beta}+f_{1}\left(\text{herdsize}_{i}\right)+f_{2}\left(\text{capital}_{i}\right)+f_{\text{spat}}\left(\text{county}_{i}\right) + \epsilon_{i}.
\end{equation}
Code doesn't work...
\section{Datasets}
\subsection{Pole Telecomm and Elevators}
  According to Lazaro Gredilla, the data sets are taken from \texttt{http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html}. 
\section{Transforming data with support $\mathcal{S}$}
Normally, the data don't lie within the interval $\left[0,1\right]$. Therefore, we must transform them according to their support. One of the distributions with universal support is the Cauchy distribution. The pdf and cdf are
\begin{align}
  q\left(x\right) &= \frac{1}{\pi\left(1+x^{2}\right)}\\
  Q\left(x\right) &= \frac{1}{\pi}\tan^{-1}\left(x\right) + \frac{1}{2}.
\end{align}
Now define $\varphi_{0}\left(x\right) = \sqrt{q\left(x\right)}$ and $\varphi_{j}\left(x\right) = \sqrt{2q\left(x\right)}\cos\left[\pi jQ\left(x\right)\right]$. Let's do one of the shape restriction models. Recall
\begin{equation}
  \varphi_{j,k}^{a}\left(x\right) = \int\limits_{0}^{x}\varphi_{j}\left(s\right)\overline{\varphi}_{k}\left(s\right)\,dx - \int\limits_{0}^{1}\int\limits_{0}^{s}\varphi_{j}\left(t\right)\overline{\varphi}_{k}\left(t\right)\,dt\,ds\;\; \text{for $j, k \geq 0$}.
\end{equation}
With the defined basis functions above,
\begin{align}
  \int\limits_{0}^{x}\varphi_{j}\left(s\right)\overline{\varphi}_{k}\left(s\right)\,dx &= \sqrt{2}\int\limits_{0}^{x} \frac{1}{\pi\left(1+x^{2}\right)}\cos \left[j\tan^{-1}\left(s\right)+\frac{\pi j}{2}\right]\,ds\\
  &= \sqrt{2}\int\limits_{Q\left(0\right)}^{Q\left(x\right)}\cos\left[\pi ju\right]\,du\quad \left(u = Q\left(x\right)\right)\\
  &= \frac{\sqrt{2}}{\pi j}\left\{\sin\left(j\tan^{-1}\left(x\right) + \frac{\pi j}{2}\right) - \sin \left(\frac{\pi j}{2}\right) \right\}\\
  \int\limits_{0}^{1}\int\limits_{0}^{s} \varphi_{j}\left(t\right)\overline{\varphi}_{k}\left(t\right)\,dt\,ds &= \int\limits_{0}^{1}\int\limits_{Q\left(0\right)}^{Q\left(s\right)}2\cos\left[\pi ju\right]\cos\left[\pi ku\right]\,du\,ds \\
  &= \int\limits_{0}^{1}\frac{\sin\left(\pi\left(j-k\right)Q\left(s\right)\right)}{\pi\left(j-k\right)}+\frac{\sin\left(\pi\left(j+k\right)Q\left(s\right)\right)}{\pi\left(j+k\right)} \,ds\\
  &\quad - \frac{\sin\left(\pi\left(j-k\right)/2\right)}{\pi\left(j-k\right)}-\frac{\sin\left(\pi\left(j+k\right)/2\right)}{\pi\left(j+k\right)}
\end{align}
Comparing with the one with support $\left[0,1\right]$ suggested in the original paper,
\begin{equation}
  \int\limits_{0}^{x}\varphi_{j}\left(s\right)\overline{\varphi}_{k}\left(s\right)\,ds = \frac{\sqrt{2}}{\pi j}\sin\left(\pi j x\right)
\end{equation}
there is another term added and care must be taken in that we shouldn't simply apply the cdf to the data and do the rest equally. The math tells us it becomes different.
\section{\texttt{ssgpr.R} manual}
List of functions:
\begin{itemize}
  \item \texttt{vbgpspectral}
  \item \texttt{minim}
  \item \texttt{ssgpr}
  \item \texttt{ssgpr\_ui}
  \item \texttt{compareSSGPvsBSAR}
\end{itemize}

Core function is \texttt{compareSSGPvsBSAR} and all else can be ignored.
\subsection{\texttt{compareSSGPvsBSAR}}
  Arguments:
  \begin{itemize}
    \item \texttt{data}
      \begin{itemize}
        \item Choose one from \texttt{c(`pendulum', `elevators', `kin', `pol', `pumadyn', `simul')}.
        \item All function similarly except for \texttt{`simul'} since it is the only option for simulation. All else are real data.
        \item If \texttt{data} is set to other than \texttt{simul}, only the main title of the plot generated is affected.
        \item \textbf{(Caution!)} If you choose one other than \texttt{simul} and set other path variable and filenames differently, then the function will not throw any error message, which could in the end be misleading! 
      \end{itemize}
    \item \texttt{fit}
      \begin{itemize}
        \item Choose one from \texttt{c(`training', `test')}.
        \item If \texttt{fit} is set to \texttt{`training'}, two of the subsequents will be ignored: \texttt{c(`fileName\_X\_tst', `fileName\_T\_tst')}. It also means one is free to not provide the argument which will then automatically be set to \texttt{NULL}.
        \item If \texttt{fit} is set to \texttt{`test'}, the function will complain if you do not supply \texttt{`fileName\_X\_tst'} and \texttt{`fileName\_T\_tst'}.
      \end{itemize}
    \item \texttt{path}
      \begin{itemize}
        \item It is a string which is assigned the absolute/relative path to the directory that contains the desired data sets. All the files should be contained in the same directory.
        \item The \texttt{path} variable should end with a forward slash \texttt{`\/'}.
      \end{itemize}
    \item \texttt{fileName\_*\_tr}, \texttt{fileName\_*\_tst}
      \begin{itemize}
        \item String variables which are assigned the respective data set names.
        \item The function will automatically concatenate \texttt{path} and \texttt{fileName\_*\_tr/fileName\_*\_tst} to load data sets.
      \end{itemize}
  \end{itemize}
  Return values
    %res_SSGP, res_BSAR, mu_BSAR, mu_SSGP , centred_SSGP, centred_BSAR
    \begin{itemize}
      \item Most importantly, it generates a plot of the fitted/predicted values of SSGP and BSAR alongside the true values displayed in points.
      \item \texttt{res\_SSGP}: Values returned from SSGP.
      \item \texttt{res\_BSAR}: Estimated parameters returned from BSAR.
      \item \texttt{mu\_SSGP}: Fitted value of SSGP if the argument \texttt{fit} is \texttt{`training'}. Predicted value if the argument \texttt{fit} is \texttt{`test'}.
      \item \texttt{mu\_BSAR}: Fitted value of BSAR if the argument \texttt{fit} is \texttt{`training'}. Predicted value if the argument \texttt{fit} is \texttt{`test'}.
      \item \texttt{centred\_SSGP}: Self-evident.
      \item \texttt{centred\_BSAR}: Self-evident.
    \end{itemize}
For an example code, refer to \texttt{demo.R}. If you pick \texttt{`simul'} for \texttt{data}, \textsf{R} will ask you to define a function that you want estimated. Use correct \textsf{R} syntax when defining your own function. For example,
\texttt{f <- function(x) tan(x) - sin(x * pi)}.
\section{Data set review}
  
\end{document}