}
# Normalizing constant for q(m_j)
I_mj <- function(a, alpha, beta) {
x <- rbeta(10000, alpha, beta)
mean(exp(-a*x)) * beta(alpha, beta)
}
# Expectation of m_j with respect to posterior q(m_j)
Emj <- function(Cm, nm1, nm0) {
I_mj(Cm, nm1 + 1, nm0) / I_mj(Cm, nm1, nm0)
}
# Vectorise Emj
Emj_v <- function(Cm, nm1, nm0) {
m <- length(Cm)
temp <- c()
for (j in 1:m) {
temp <- c(temp, Emj(Cm[j], nm1, nm0))
}
temp
}
# Expectation of log(Gamma(s_j)) with respect to posterior q(s_j)
E_lgamma_s <- function(a_s, beta_s) {
mean(lgamma(rgamma(10000, shape = a_s, scale = beta_s)))
}
# Expectation of log(Gamma(s_j * m_j)) with respect to posterior q(s_j) & q(m_j)
E_lgamma_sm <- function(a_s, beta_s, Cm, nm1, nm0) {
mean(lgamma(rgamma(10000, shape = a_s, scale = beta_s) * m_sampling(10000, Cm, nm1, nm0)))
}
# Expectation of log(Gamma(s_j - s_j * m_j - 1)) with respect to posterior q(s_j) & q(m_j)
E_lgamma_s_sm_1 <- function(a_s, beta_s, Cm, nm1, nm0) {
s <- rgamma(10000, shape = a_s, scale = beta_s)
m <- m_sampling(10000, Cm, nm1, nm0)
mean(lgamma(s - s * m - 1))
}
temp1 <- 0
for (i in 1:N) {
for (j in 1:M) {
temp1 <- temp1 + phi[i, j] * E_lgamma_s(a_s, beta_s[j]) - E_lgamma_sm(a_s, beta_s[j], Cm[j], nm1, nm0) - E_lgamma_s_sm_1(a_s, beta_s[j], Cm[j], nm1, nm0) + (a_s * beta_s[j] * Emj(Cm[j], nm1, nm0) - 1) * log(y[i]) + (a_s * beta_s[j] * (1 - Emj(Cm[j], nm1, nm0)) - 1) * log(1 - y[i])
print(paste0('#j: ', j, ' #i: ', i, ' temp1: ', temp1))
}
}
# Package for Dirichlet distribution
## Usage: rdirichlet, ddirichlet
library(gtools)
# Acceptance-Rejection algorithm for q(m_j)
m_sampling <- function(n, Cm, nm1, nm0) {
f_div_g <- function(x) exp(-Cm * x) * x^(nm1-1) * (1-x)^(nm0-1)
M <- optimize(f_div_g, interval = c(0, 1), maximum = TRUE)$objective
temp <- c()
while (length(temp) < n) {
u <- runif(1)
x <- runif(1)
if (M * u < f_div_g(x)) temp <- c(temp, x)
}
temp
}
# Normalizing constant for q(m_j)
I_mj <- function(a, alpha, beta) {
x <- rbeta(10000, alpha, beta)
mean(exp(-a*x)) * beta(alpha, beta)
}
# Expectation of m_j with respect to posterior q(m_j)
Emj <- function(Cm, nm1, nm0) {
I_mj(Cm, nm1 + 1, nm0) / I_mj(Cm, nm1, nm0)
}
# Vectorise Emj
Emj_v <- function(Cm, nm1, nm0) {
m <- length(Cm)
temp <- c()
for (j in 1:m) {
temp <- c(temp, Emj(Cm[j], nm1, nm0))
}
temp
}
# Expectation of log(Gamma(s_j)) with respect to posterior q(s_j)
E_lgamma_s <- function(a_s, beta_s) {
mean(lgamma(rgamma(10000, shape = a_s, scale = beta_s)))
}
# Expectation of log(Gamma(s_j * m_j)) with respect to posterior q(s_j) & q(m_j)
E_lgamma_sm <- function(a_s, beta_s, Cm, nm1, nm0) {
mean(lgamma(rgamma(10000, shape = a_s, scale = beta_s) * m_sampling(10000, Cm, nm1, nm0)))
}
# Expectation of log(Gamma(s_j - s_j * m_j - 1)) with respect to posterior q(s_j) & q(m_j)
E_lgamma_s_sm_1 <- function(a_s, beta_s, Cm, nm1, nm0) {
s <- rgamma(10000, shape = a_s, scale = beta_s)
m <- m_sampling(10000, Cm, nm1, nm0)
mean(lgamma(s - s * m - 1))
}
# Lower bound
LB <- function(y, phi, a, a_s, beta_s, Cm, nm1, nm0, N, M) {
# temp1
temp1 <- 0
for (i in 1:N) {
for (j in 1:M) {
temp1 <- temp1 + phi[i, j] * E_lgamma_s(a_s, beta_s[j]) - E_lgamma_sm(a_s, beta_s[j], Cm[j], nm1, nm0) - E_lgamma_s_sm_1(a_s, beta_s[j], Cm[j], nm1, nm0) + (a_s * beta_s[j] * Emj(Cm[j], nm1, nm0) - 1) * log(y[i]) + (a_s * beta_s[j] * (1 - Emj(Cm[j], nm1, nm0)) - 1) * log(1 - y[i])
}
}
# temp2
temp2 <- 0
for (j in 1:M) {
for (i in 1:N) {
temp2 <- temp2 + digamma(phi[i, j] + a) - digamma(sum(phi) + M * a)
}
}
# temp3
temp3 <- 0
for (j in 1:M) {
temp3 <- temp3 - a_s * beta_s[j] + Cm[j] * Emj(Cm[j], nm1, nm0) + log(I_mj(Cm[j], nm1, nm0))
}
# temp4
temp4 <- 0
for (j in 1:M) {
temp4 <- temp4 - a_s * beta_s[j] - 1 / (a_s - 1)
}
temp4 <- temp4 - M * lgamma(a_s) + sum(phi * log(phi))
# Final lower bound
temp1 - temp2 + temp3 - temp4
}
# Variational approximation for Beta Mixture
## y: N x 1 vector
## a, a_s, b_s, nm1, nm0: scalar
## M: number of mixtures (scalar)
BMVB <- function(y, M, a, a_s, b_s, nm1, nm0) {
# Initialize variational parameters
N <- length(y)
phi <- rdirichlet(N, rep(a, M))
beta_s <- rep(b_s, M)
LB_old <- -Inf
# Coordinate ascent
while (TRUE) {
## Cm
Cm <- -apply(phi * log(y / (1 - y)), 2, sum) * (a_s * beta_s)
print(paste0('Cm ', Cm))
## beta_s
beta_s <- 1 / (-((Emj_v(Cm, nm1, nm0) * apply(phi * log(y), 2, sum)) + ((1 - Emj_v(Cm, nm1, nm0)) * apply(phi * log(1 - y), 2, sum))) + 1/b_s)
print(paste0('beta_s ', beta_s))
## phi_ij
for (j in 1:M) {
for (i in 1:N) {
phi[i, j] <- (y[i] / (1 - y[i]))^(a_s * beta_s[j] * Emj(Cm[j], nm1, nm0)) * (1 - y[i])^(a_s * beta_s[j]) * exp( digamma(sum(phi[, j]) + a) - digamma(sum(phi) + M * a)) / (y[i] * (1 - y[i]))
}
}
# Monitor convergence
LB_new <- LB(y, phi, a, a_s, beta_s, Cm, nm1, nm0, N, M)
if (abs(LB_new - LB_old) < 0.000001) break
else LB_old <- LB_new
}
list('phi' = phi, 'beta_s' = beta_s, 'Cm' = Cm, 'LB' = LB_new)
}
M <- 3
N <- 300
## Hyperpriors
a <- 3
a_s <- 3
b_s <- 10^2
nm1 <- 2
nm0 <- 2
## Sampling priors from hyperpriors
s <- rgamma(M, shape = a_s, scale = b_s)
m <- rbeta(M, nm1, nm0)
lambda <- rdirichlet(1, rep(a, M))
## Generating mixture data (Avoid 'for' loops for performance reasons)
components <- sample(1:M, prob = lambda, size = N, replace = TRUE)
y <- rbeta(n = N, shape1 = s[components] * m[components], shape2 = s[components] * (1 - m[components]))
phi <- rdirichlet(N, rep(a, M))
beta_s <- rep(b_s, M)
LB_old <- -Inf
phi
Cm <- -apply(phi * log(y / (1 - y)), 2, sum) * (a_s * beta_s)
log(y/(1-y))
my_fun <- function(x, Cm, nm1, nm0) exp(Cm * x) * x^(nm1-1) * (1-x)^(nm0-1)
curve(my_fun(x, -2, 3, 3))
curve(my_fun(x, 3, 3, 3))
curve(my_fun(x, -20, 3, 3))
beta_s <- 1 / (-((Emj_v(Cm, nm1, nm0) * apply(phi * log(y), 2, sum)) + ((1 - Emj_v(Cm, nm1, nm0)) * apply(phi * log(1 - y), 2, sum))) + 1/b_s)
print(paste0('beta_s ', beta_s))
m_sampling(10, Cm[1], nm1, nm0)
warnings()
curve(my_fun(x, Cm[1], nm1, nm0))
optimize(my_fun(x, Cm[1], nm1, nm0), c(0,1), maximum=TRUE)
my_fun2 <- my_fun(x, Cm[1], nm1, nm0)
my_fun2 <- function(x) my_fun(x, Cm[1], nm1, nm0)
optimize(my_fun2, c(0,1), maximum=TRUE)
log(y/(1-y))
a_s * b_s
beta_s <- rep(b_s, M)
a_s * beta_s
mean(rgamma(10000, shape = 3, scale = 100))
mean(rgamma(10000, shape = 3, scale = 100))
mean(rgamma(10000, shape = 3, scale = 100))
mean(rgamma(10000, shape = 3, scale = 100))
mean(rgamma(10000, shape = 3, scale = 100))
mean(rgamma(10000, shape = 3, scale = 100))
mean(rgamma(10000, shape = 3, scale = 100))
mean(rgamma(10000, shape = 3, scale = 100))
apply(phi * log(y / (1 - y)), 2, sum)
Emj_v(Cm, nm1, nm0)
my_fun3 <- function(x) lgamma(x) * x^3 * (1-x)^(4)
integrate(my_fun3, c(0,1))
integrate(my_fun3, lower = 0, upper = 1)
mean(lgamma(rbeta(10000, 4, 5)) * beta(4, 5))
my_fun3 <- function(x) lgamma(x) * x^5 * exp(-5*x)
integrate(my_fun3, lower = 0)
Cm
m_sampling(10, Cm[1], nm1, nm9)
m_sampling(10, Cm[1], nm1, nm0)
warnings()
my_fun
my_fun1
my_fun2
optimize(my_fun2, c(0,1), maximum=TRUE)
my_fun2(runif(1))
my_fun2(runif(1))
my_fun2(runif(1))
my_fun2(runif(1))
nm1
nm2
nm0
exp(Cm[1] * runif(1))
runif(!)
runif(1)
Cm[1] * runif(1)
Cm
Cm[1] * runif(1)
Cm
Cm[1] * runif(1)
Cm[1] * runif(1)
Cm[1] * runif(1)
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.3))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
exp(-Cm[1] * runif(1, 0, 0.5))
m_sampling(3, Cm[1], nm1, nm0)
m_sampling(10, 3, 2, 3)
m_sampling(10, -3, 2, 3)
m_sampling(10, -5, 2, 3)
hist(m_sampling(10, -5, 2, 3), nclass = 20)
hist(m_sampling(100, -5, 2, 3), nclass = 20)
hist(m_sampling(100, -5, 2, 3), probability = TRUE, nclass = 20)
hist(m_sampling(100, 10, 2, 3), probability = TRUE, nclass = 20)
hist(m_sampling(100, 3, 2, 3), probability = TRUE, nclass = 20)
hist(m_sampling(100, 4, 2, 3), probability = TRUE, nclass = 20)
hist(m_sampling(100, 4, 2, 3), probability = TRUE, break = 20)
hist(m_sampling(100, 4, 2, 3), probability = TRUE, breaks = 20)
hist(m_sampling(100, 20, 2, 3), probability = TRUE, breaks = 20)
x
rm(x)
x
curve(my_fun2(x, 100, 2, 2))
curve
my_fun
my_fun4 <- function(x) my_fun(x, 100, 2, 2)
curve(my_fun4)
my_fun4 <- function(x) my_fun(x, 1000, 2, 2)
curve(my_fun4)
integrate(my_fun4, lower = 0, upper = 1)
M <- 3
N <- 100
## Hyperpriors
a <- 3
a_s <- 3
b_s <- 10^2
nm1 <- 2
nm0 <- 2
## Sampling priors from hyperpriors
s <- rgamma(M, shape = a_s, scale = b_s)
m <- rbeta(M, nm1, nm0)
lambda <- rdirichlet(1, rep(a, M))
## Generating mixture data (Avoid 'for' loops for performance reasons)
components <- sample(1:M, prob = lambda, size = N, replace = TRUE)
y <- rbeta(n = N, shape1 = s[components] * m[components], shape2 = s[components] * (1 - m[components]))
phi <- rdirichlet(N, rep(a, M))
beta_s <- rep(b_s, M)
LB_old <- -Inf
Cm <- -apply(phi * log(y / (1 - y)), 2, sum) * (a_s * beta_s)
print(paste0('Cm ', Cm))
## beta_s
beta_s <- 1 / (-((Emj_v(Cm, nm1, nm0) * apply(phi * log(y), 2, sum)) + ((1 - Emj_v(Cm, nm1, nm0)) * apply(phi * log(1 - y), 2, sum))) + 1/b_s)
print(paste0('beta_s ', beta_s))
## phi_ij
for (j in 1:M) {
for (i in 1:N) {
phi[i, j] <- (y[i] / (1 - y[i]))^(a_s * beta_s[j] * Emj(Cm[j], nm1, nm0)) * (1 - y[i])^(a_s * beta_s[j]) * exp( digamma(sum(phi[, j]) + a) - digamma(sum(phi) + M * a)) / (y[i] * (1 - y[i]))
}
}
phi
h <- function(x,p,q,r) { p*log(x)-q*x^2-log(r+x^(-2)) }
h1 <- function(x,p,q,r) { p/x-2*q*x+2/(r*x^3+x) } #first derivative of h
h2 <- function(x,p,q,r) { -p/x^2-2*q-2*(3*r*x^2+1)/(r*x^3+x)^2 } #second derivative of h
hmaxpt <- function(p,q,r) { sqrt((p*r-2*q+sqrt((p*r-2*q)^2+8*q*r*(p+2)))/(4*q*r)) }
logH <- function(p,q,r){
mu0 <- hmaxpt(p,q,r)
sig0 <- (-h2(mu0,p,q,r))^(-0.5)
hmu0 <- h(mu0,p,q,r)
sig02 <- sig0*sqrt(2)
lowerlimit <- (-mu0)/sig02
integrand <- function(u) {exp(h(mu0+u*sig02,p,q,r)-hmu0)}
b <- 1
epsilon <- 1
while (epsilon > 1.0e-5) {
b <- 2*b
if (-b > lowerlimit) {
epsilon <- max(integrand(b),integrand(-b)) } else {epsilon <- integrand(b)} }
if (-b > lowerlimit) {I0 <- integrate(integrand, lower=-b, upper=b)$value
} else {I0 <- integrate(integrand, lower=lowerlimit, upper=b)$value}
hmu0+log(sig02)+log(I0)}
exp(logH(18, 100, 4))
phi <- rdirichlet(N, rep(a, M))
exp(digamma(sum(phi[,1]) + a))
exp(digamma(sum(phi[,1]) + a) - digamma(sum(phi) + M * a))
exp(digamma(sum(phi[,2]) + a) - digamma(sum(phi) + M * a))
exp(digamma(sum(phi[,3]) + a) - digamma(sum(phi) + M * a))
beta_s <- rep(b_s, M)
beta_s <- 1 / (-((Emj_v(Cm, nm1, nm0) * apply(phi * log(y), 2, sum)) + ((1 - Emj_v(Cm, nm1, nm0)) * apply(phi * log(1 - y), 2, sum))) + 1/b_s)
for (j in 1:M) {
for (i in 1:N) {
phi[i, j] <- (y[i] / (1 - y[i]))^(a_s * beta_s[j] * Emj(Cm[j], nm1, nm0)) * (1 - y[i])^(a_s * beta_s[j]) * exp( digamma(sum(phi[, j]) + a) - digamma(sum(phi) + M * a)) / (y[i] * (1 - y[i]))
}
}
phi
M <- 3
N <- 300
## Hyperpriors
a <- 3
a_s <- 3
b_s <- 10^2
nm1 <- 2
nm0 <- 2
## Sampling priors from hyperpriors
s <- rgamma(M, shape = a_s, scale = b_s)
m <- rbeta(M, nm1, nm0)
lambda <- rdirichlet(1, rep(a, M))
## Generating mixture data (Avoid 'for' loops for performance reasons)
components <- sample(1:M, prob = lambda, size = N, replace = TRUE)
y <- rbeta(n = N, shape1 = s[components] * m[components], shape2 = s[components] * (1 - m[components]))
N <- length(y)
phi <- rdirichlet(N, rep(a, M))
beta_s <- rep(b_s, M)
LB_old <- -Inf
Cm <- rep(2, M)
beta_s <- 1 / (-((Emj_v(Cm, nm1, nm0) * apply(phi * log(y), 2, sum)) + ((1 - Emj_v(Cm, nm1, nm0)) * apply(phi * log(1 - y), 2, sum))) + 1/b_s)
for (j in 1:M) {
for (i in 1:N) {
phi[i, j] <- exp(E_lgamma_s(a_s, beta_s[j]) - E_lgamma_sm(a_s, beta_s[j], Cm[j], nm1, nm0) - E_lgamma_s_sm(a_s, beta_s[j], Cm[j], nm1, nm0)) (y[i] / (1 - y[i]))^(a_s * beta_s[j] * Emj(Cm[j], nm1, nm0)) * (1 - y[i])^(a_s * beta_s[j]) * exp( digamma(sum(phi[, j]) + a) - digamma(sum(phi) + M * a)) / (y[i] * (1 - y[i]))
}
}
# Package for Dirichlet distribution
## Usage: rdirichlet, ddirichlet
library(gtools)
# Acceptance-Rejection algorithm for q(m_j)
m_sampling <- function(n, Cm, nm1, nm0) {
f_div_g <- function(x) exp(-Cm * x) * x^(nm1-1) * (1-x)^(nm0-1)
M <- optimize(f_div_g, interval = c(0, 1), maximum = TRUE)$objective
temp <- c()
while (length(temp) < n) {
u <- runif(1)
x <- runif(1)
if (M * u < f_div_g(x)) temp <- c(temp, x)
}
temp
}
# Normalizing constant for q(m_j)
I_mj <- function(a, alpha, beta) {
x <- rbeta(10000, alpha, beta)
mean(exp(-a*x)) * beta(alpha, beta)
}
# Expectation of m_j with respect to posterior q(m_j)
Emj <- function(Cm, nm1, nm0) {
I_mj(Cm, nm1 + 1, nm0) / I_mj(Cm, nm1, nm0)
}
# Vectorise Emj
Emj_v <- function(Cm, nm1, nm0) {
m <- length(Cm)
temp <- c()
for (j in 1:m) {
temp <- c(temp, Emj(Cm[j], nm1, nm0))
}
temp
}
# Expectation of log(Gamma(s_j)) with respect to posterior q(s_j)
E_lgamma_s <- function(a_s, beta_s) {
mean(lgamma(rgamma(10000, shape = a_s, scale = beta_s)))
}
# Expectation of log(Gamma(s_j * m_j)) with respect to posterior q(s_j) & q(m_j)
E_lgamma_sm <- function(a_s, beta_s, Cm, nm1, nm0) {
mean(lgamma(rgamma(10000, shape = a_s, scale = beta_s) * m_sampling(10000, Cm, nm1, nm0)))
}
# Expectation of log(Gamma(s_j - s_j * m_j - 1)) with respect to posterior q(s_j) & q(m_j)
E_lgamma_s_sm <- function(a_s, beta_s, Cm, nm1, nm0) {
s <- rgamma(10000, shape = a_s, scale = beta_s)
m <- m_sampling(10000, Cm, nm1, nm0)
mean(lgamma(s - s * m))
}
for (j in 1:M) {
for (i in 1:N) {
phi[i, j] <- exp(E_lgamma_s(a_s, beta_s[j]) - E_lgamma_sm(a_s, beta_s[j], Cm[j], nm1, nm0) - E_lgamma_s_sm(a_s, beta_s[j], Cm[j], nm1, nm0)) (y[i] / (1 - y[i]))^(a_s * beta_s[j] * Emj(Cm[j], nm1, nm0)) * (1 - y[i])^(a_s * beta_s[j]) * exp( digamma(sum(phi[, j]) + a) - digamma(sum(phi) + M * a)) / (y[i] * (1 - y[i]))
}
}
for (j in 1:M) {
for (i in 1:N) {
phi[i, j] <- exp(E_lgamma_s(a_s, beta_s[j]) - E_lgamma_sm(a_s, beta_s[j], Cm[j], nm1, nm0) - E_lgamma_s_sm(a_s, beta_s[j], Cm[j], nm1, nm0)) * (y[i] / (1 - y[i]))^(a_s * beta_s[j] * Emj(Cm[j], nm1, nm0)) * (1 - y[i])^(a_s * beta_s[j]) * exp( digamma(sum(phi[, j]) + a) - digamma(sum(phi) + M * a)) / (y[i] * (1 - y[i]))
}
}
phi <- rdirichlet(N, rep(a, M))
beta_s <- rep(b_s, M)
Cm <- rep(2, M)
LB_old <- -Inf
beta_s <- 1 / (-((Emj_v(Cm, nm1, nm0) * apply(phi * log(y), 2, sum)) + ((1 - Emj_v(Cm, nm1, nm0)) * apply(phi * log(1 - y), 2, sum))) + 1/b_s)
print(paste0('beta_s ', beta_s))
for (j in 1:M) {
for (i in 1:N) {
phi[i, j] <- exp(E_lgamma_s(a_s, beta_s[j]) - E_lgamma_sm(a_s, beta_s[j], Cm[j], nm1, nm0) - E_lgamma_s_sm(a_s, beta_s[j], Cm[j], nm1, nm0)) * (y[i] / (1 - y[i]))^(a_s * beta_s[j] * Emj(Cm[j], nm1, nm0)) * (1 - y[i])^(a_s * beta_s[j]) * exp( digamma(sum(phi[, j]) + a) - digamma(sum(phi) + M * a)) / (y[i] * (1 - y[i]))
print(phi[i,j])
}
}
phi
sum(phi)
apply(phi, 2, sum)
apply(phi, 1, sum)
phi2 <- rdirichlet(N, rep(a, M))
apply(phi2, 1, sum)
data<-read.table("/home/lionel/Documents/PhD/GLMM_WS/data/rikz.txt",sep=" ",head=TRUE)
path=getwd()
source(paste(path,'/GP_code.R',sep=''))
path
setwd('~/Desktop/VB/GPVB/GPVB')
path=getwd()
source(paste(path,'/GP_code.R',sep=''))
y_tr=scan(paste(path,'/PendulumData/T_tr.txt',sep=''))
ntr=length(y_tr)
y_tst=scan(paste(path,'/PendulumData/T_tst.txt',sep=''))
ntst=length(y_tst)
# X
d=9
X_tr=matrix(scan(paste(path,'/PendulumData/X_tr.txt',sep='')),nr=ntr,nc=d,byrow=T)
X_tst=matrix(scan(paste(path,'/PendulumData/X_tst.txt',sep='')),nr=ntr,nc=d,byrow=T)
str(X_tst)
head(X_tst)
write.csv("matrix.csv", X_tr)
write.csv(X_tr, "matrix.csv")
head(X_tr)
